{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "pd.set_option('max_colwidth', 150)\n",
    "from tqdm import tqdm\n",
    "# import os\n",
    "# import time\n",
    "import json\n",
    "tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
    "ps = PorterStemmer()\n",
    "file = \"../../raw_data/vax_train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"words_dictionary.json\") as f: D1 = sorted(set([s.lower() for s in json.load(f).keys()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual = [\"covid\", \"lockdown\"]\n",
    "# words = list(set([ps.stem(x.lower()) for x in set(list(words.words()) + list(english_words_set) + manual + D1)]))\n",
    "words = list(set([x.lower() for x in D1+manual]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(string,\n",
    "            tokenizer = nltk.RegexpTokenizer(r\"\\w+\"),\n",
    "            ps = PorterStemmer(),\n",
    "            stopwords = stopwords.words('english')):\n",
    "    '''\n",
    "    - A function to process a string and return a list of tokens.\n",
    "    - We tokenize the string, remove stopwords and numbers, and\n",
    "        finally stem the tokens to keep them in a list.\n",
    "    - This function will be used in all cases uniformly so that \n",
    "        we can compare \"APPLES WITH APPLES\".\n",
    "    '''\n",
    "    # global inters\n",
    "    string = string.split()\n",
    "    # print(a)\n",
    "    string = [\n",
    "                word for word in string \n",
    "                if len(word) \n",
    "                #    and not word.startswith(\"http\")\n",
    "                #    and word[0] != \"@\"\n",
    "                #    and word[0] != \"#\"\n",
    "                #    and word[0] != \".\"\n",
    "                #    and word[0] != \"!\"\n",
    "                #    and word[0] != \"?\"\n",
    "                #    and word[0] != \"\\n\"\n",
    "                #    and word[0] != \"\\t\"\n",
    "    ]\n",
    "    # string = \" \".join(string)\n",
    "    # string = tokenizer.tokenize(string.lower()) # tokenize\n",
    "    # string = [\n",
    "    #             # ps.stem(fl) for fl in string  # stem tokens\n",
    "    #             fl for fl in string  # stem tokens\n",
    "    #             # if not fl.isnumeric()  # remove numbers\n",
    "    #             # and fl not in stopwords  # remove stopwords\n",
    "    #             # and fl in words\n",
    "    # ]\n",
    "    # for x in string:\n",
    "    #     if x.lower() not in words:\n",
    "    #         inters.append(x)\n",
    "    return \" \".join(string)  #.lower()  # returns processed string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(file).T.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4392/4392 [00:00<00:00, 125476.00it/s]\n"
     ]
    }
   ],
   "source": [
    "inters = []\n",
    "i = 0\n",
    "data2 = {}\n",
    "for key, value in tqdm(data.items()):\n",
    "    data2[key] = value\n",
    "    data2[key][\"tweet\"] = process(value[\"tweet\"])\n",
    "    # if i == 1000:\n",
    "    #     break\n",
    "    # i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data2).T.to_csv(\"original.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "95b59b4b0e72d3e94105c3ab4f1a1e6e746e4c2a7c235241251baf92fb36381f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
