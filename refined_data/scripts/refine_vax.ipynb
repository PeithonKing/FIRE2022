{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "pd.set_option('max_colwidth', 150)\n",
    "from tqdm import tqdm\n",
    "# import os\n",
    "# import time\n",
    "import json\n",
    "tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
    "ps = PorterStemmer()\n",
    "file = \"../../raw_data/vax_train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"words_dictionary.json\") as f: D1 = sorted(list(json.load(f).keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual = [\"covid\", \"lockdown\"]\n",
    "# words = list(set([ps.stem(x.lower()) for x in set(list(words.words()) + list(english_words_set) + manual + D1)]))\n",
    "words = list(set([x.lower() for x in D1+manual]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "228574"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(string,\n",
    "            tokenizer = nltk.RegexpTokenizer(r\"\\w+\"),\n",
    "            ps = PorterStemmer(),\n",
    "            stopwords = stopwords.words('english')):\n",
    "    '''\n",
    "    - A function to process a string and return a list of tokens.\n",
    "    - We tokenize the string, remove stopwords and numbers, and\n",
    "        finally stem the tokens to keep them in a list.\n",
    "    - This function will be used in all cases uniformly so that \n",
    "        we can compare \"APPLES WITH APPLES\".\n",
    "    '''\n",
    "    global inters\n",
    "    a = string.split()\n",
    "    # print(a)\n",
    "    string = [\n",
    "                word.lower() for word in a \n",
    "                if len(word) and\n",
    "                   not word.startswith(\"http\") and\n",
    "                   word[0] != '@' and\n",
    "                   word[0] != '#' and\n",
    "                   word[0] != '.' and\n",
    "                   word[0] != '!' and\n",
    "                   word[0] != '?' and\n",
    "                   word[0] != '\\n' and\n",
    "                   word[0] != '\\t'\n",
    "    ]\n",
    "    string = \" \".join(string)\n",
    "    string = tokenizer.tokenize(string.lower()) # tokenize\n",
    "    tokens = [\n",
    "                # ps.stem(fl) for fl in string  # stem tokens\n",
    "                fl for fl in string  # stem tokens\n",
    "                if not fl.isnumeric() and  # remove numbers\n",
    "                fl not in stopwords and  # remove stopwords\n",
    "                fl in words\n",
    "    ]\n",
    "    # for x in tokens:\n",
    "    #     if x.lower() not in words:\n",
    "    #         inters.append(x)\n",
    "    return \" \".join(tokens)  # returns processed string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(file).T.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|â–Œ         | 220/4392 [00:30<09:39,  7.20it/s]"
     ]
    }
   ],
   "source": [
    "inters = []\n",
    "for key, value in tqdm(data.items()):\n",
    "    data[key][\"tweet\"] = process(value[\"tweet\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inters = sorted(list(set(inters)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(inters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(inters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data).T.to_csv(\"data.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0839f674c90357cf57b84737cbb78f6691416cdd39bc1077f945d4066e99dfa5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
